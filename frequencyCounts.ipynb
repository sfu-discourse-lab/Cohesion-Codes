{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba65cb2-9635-4a6f-aa8e-2f568fc7f0b5",
   "metadata": {},
   "source": [
    "# Frequency Counts for Thematic Lexemes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d006d0-9b16-485a-bd8b-6d8b654e4a93",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8840f894-ab98-4f7a-b4dc-c51c7052bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from tabulate import tabulate\n",
    "\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa834ab-a312-4627-8bed-00ca0e0b284d",
   "metadata": {},
   "source": [
    "## Reading in Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cc48c1d-255e-43a5-9d7f-074357398750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking path\n",
    "# print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79685ef0-2575-4186-ace1-818bed592453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting file paths\n",
    "lexemesPath = 'thematiclexemes.txt'\n",
    "textPath = 'Tension_OpeningScene.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a564ee-a93d-425d-8ac2-7df11b8149d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading files from path\n",
    "with open(lexemesPath) as f:\n",
    "    # storing lexemes as a list\n",
    "    lexemes = f.read().split()\n",
    "with open(textPath) as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dafa6e-2e44-4953-9c4a-125c47416a7a",
   "metadata": {},
   "source": [
    "## Frequency Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bba7ab8c-3b0b-4fb6-9ff2-b8e24428513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexemeCounter(lexemeList, text):\n",
    "    '''\n",
    "    takes a list of lexemes and a string of text as input and returns a dictionary, \n",
    "    where each key is a lexeme and the values are the associated frequency counts\n",
    "    '''\n",
    "    cntDict = {}\n",
    "    # tokenizing the text\n",
    "    tokenizedText = word_tokenize(text)\n",
    "    \n",
    "    # creating a list of the stems in the text\n",
    "    lemmatizedText = [stemmer.stem(token) for token in tokenizedText]\n",
    "\n",
    "    # looping over each lexeme in the lexeme list\n",
    "    for lexeme in lexemes:\n",
    "        # checking how many times a lexeme stem shows up in the list of stems \n",
    "        cnt = lemmatizedText.count(stemmer.stem(lexeme))\n",
    "        cntDict[lexeme] = cnt\n",
    "    return cntDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2ed9a3-55ef-4df9-8c10-8c267facff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexeme         Count\n",
      "-----------  -------\n",
      "edge               1\n",
      "drugs              3\n",
      "hold               1\n",
      "roar               1\n",
      "bats               3\n",
      "diving             1\n",
      "voice              1\n",
      "animals            1\n",
      "hell               1\n",
      "bastard            1\n",
      "narcotics          1\n",
      "grass              1\n",
      "mescaline          1\n",
      "acid               1\n",
      "cocaine            1\n",
      "uppers             1\n",
      "downers            1\n",
      "screamers          1\n",
      "laughers           1\n",
      "ether              5\n",
      "amyls              1\n",
      "frenzy             1\n",
      "depths             1\n",
      "binge              1\n",
      "snort              1\n",
      "stupor             1\n",
      "consumption        1\n",
      "blood              1\n",
      "brain              1\n",
      "screaming          1\n",
      "yelling            1\n",
      "muttered           1\n",
      "moaning            1\n",
      "grappling          1\n",
      "drag               1\n",
      "swooping           1\n",
      "screeching         1\n",
      "lightheaded        1\n",
      "terrible           1\n",
      "huge               2\n",
      "goddamn            2\n",
      "poor               2\n",
      "ill                1\n",
      "dangerous          1\n",
      "raw                1\n",
      "helpless           1\n",
      "rotten             1\n",
      "horrible           1\n",
      "spastic            1\n",
      "twisted            1\n",
      "depraved           1\n",
      "locked             1\n",
      "worried            1\n",
      "slumped            1\n",
      "demented           1\n",
      "slobbering         1\n",
      "suddenly           1\n",
      "completely         1\n",
      "extremely          1\n"
     ]
    }
   ],
   "source": [
    "cntDict = lexemeCounter(lexemes, text)\n",
    "headers = [\"Lexeme\", \"Count\"]\n",
    "print(tabulate(cntDict.items(), headers = headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7684c-3a66-4949-a6b0-40489a5c8ae6",
   "metadata": {},
   "source": [
    "## Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62b0c2f2-a994-443c-bb2f-33bd5eddb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing the text\n",
    "tokenizedText = word_tokenize(text)\n",
    "\n",
    "# removing stop words\n",
    "newText = \" \".join([token for token in tokenizedText if token.lower() not in stopWords])\n",
    "\n",
    "# saving to file\n",
    "with open('SceneContent.txt', 'w') as f:\n",
    "    f.write(newText)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
